# -------- TOP-LEVEL ENV SETTINGS (applies to the whole run) --------
env_settings:
  num_envs: 1        # Editor uses 1 env; increase only for standalone builds
  seed: 42           # optional

engine_settings:
  time_scale: 1
  target_frame_rate: -1
  capture_frame_rate: 0

# -------- BEHAVIOR CONFIGS --------
behaviors:
  Reversi:
    trainer_type: ppo

    hyperparameters:
      batch_size: 512
      buffer_size: 16384
      learning_rate: 3.0e-4
      beta: 1.0e-3
      epsilon: 0.2
      lambd: 0.95
      num_epoch: 3
      learning_rate_schedule: linear
      beta_schedule: linear
      epsilon_schedule: linear

    network_settings:
      normalize: true
      hidden_units: 256
      num_layers: 2

    reward_signals:
      extrinsic:
        gamma: 0.99
        strength: 1.0
        network_settings:
          normalize: false
          hidden_units: 128
          num_layers: 2

    self_play:
      save_steps: 20000
      team_change: 200000
      swap_steps: 50000
      window: 20
      play_against_latest_model_ratio: 0.2
      initial_elo: 1200.0

    max_steps: 2000000
    time_horizon: 64
    summary_freq: 500